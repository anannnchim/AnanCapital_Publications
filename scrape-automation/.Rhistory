#load libs
library(tidyverse)
library(rvest)
#nse top gainers
url <- 'https://www.rforseo.com/sitemap.xml'
url
url_html <- read_html(url)
url_html
nbr_url <- url_html %>%
html_nodes("loc")  %>%
length()
row <- data.frame(Sys.Date(), nbr_url)
row
write_csv(row,paste0('data/xml_url_count.csv'),append = T)
library(readr)
xml_url_count <- read_csv("data/xml_url_count.csv")
View(xml_url_count)
setwd("/Users/nanthawat/Documents/GitHub/scrape-automation")
xml_url_count
xml_url_count %>% tail()
write_csv(row,paste0('data/xml_url_count.csv'),append = T)
#load libs
library(tidyverse)
library(rvest)
#nse top gainers
url <- 'https://www.rforseo.com/sitemap.xml'
# extract html
url_html <- read_html(url)
#table extraction
nbr_url <- url_html %>%
html_nodes("loc")  %>%
length()
row <- data.frame(Sys.Date(), nbr_url)
write_csv(row,paste0('data/xml_url_count.csv'),append = T)
url_absolute()
url_html
library(readr)
xml_url_count <- read_csv("data/xml_url_count.csv")
xml_url_count %>% tail()
setwd("/Users/nanthawat/Documents/GitHub/scrape-automation")
